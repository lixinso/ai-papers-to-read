# Best AI Papers to Read
### [That are publicly available]

## Papers

| Title | Link | Author | Date |
|-------|------|--------|------|
| MoBA: Mixture of Block Attention for Long-Context LLMs | [arXiv](https://arxiv.org/abs/2502.13189) | - | - |
| Native Sparse Attention: Hardware-Aligned and Natively Trainable Sparse Attention | [arXiv](https://arxiv.org/abs/2502.11089) | - | - |
| Foundations of Large Language Models | [arXiv](https://arxiv.org/abs/2501.09223) | - | - |
| DeepSeek-V3 Technical Report | [GitHub](https://github.com/deepseek-ai/DeepSeek-V3/blob/main/DeepSeek_V3.pdf) | - | - |
| Adaptive In-Conversion Team Building For Language Model Agent | [arXiv](https://arxiv.org/pdf/2405.19425) | - | - |
| Agent AI Towards a Holistic Intelligence | [Microsoft](https://www.microsoft.com/en-us/research/uploads/prod/2024/02/AgentAI_p.pdf?utm_source=chatgpt.com) | - | - |
| Large Language Model-Brained GUI Agents: A Survey | [arXiv](https://arxiv.org/pdf/2411.18279) | - | - |
| MLE-bench: Evaluating Machine Learning Agents on Machine Learning Engineering | [arXiv](https://arxiv.org/abs/2410.07095) | OpenAI | 24 Oct 2024 |
| Agent AI: Surveying the Horizons of Multimodal Interaction | [arXiv](https://arxiv.org/abs/2401.03568) | - | - |
| The Llama 3 Herd of Models | [PDF](https://scontent-sea1-1.xx.fbcdn.net/v/t39.2365-6/468347782_9231729823505907_4580471254289036098_n.pdf?_nc_cat=110&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=kMEnijIEZ-gQ7kNvgGkvbgV&_nc_zt=14&_nc_ht=scontent-sea1-1.xx&_nc_gid=AArxIIwO-RKxc0VHEWEXrCy&oh=00_AYBtVpVUKJJ3gf-Ev83Js4tUNmA_eQCHifdaJapFuVCJtA&oe=67508F80), [Meta AI](https://ai.meta.com/research/publications/the-llama-3-herd-of-models/), [Blog](https://ai.meta.com/blog/meta-llama-3-1/), [Repo](./papers/The%20Llama%203%20Herd%20of%20Models/README.md) | - | - |
| Magentic-One: A Generalist Multi-Agent System for Solving Complex Tasks | [Microsoft Article](https://www.microsoft.com/en-us/research/articles/magentic-one-a-generalist-multi-agent-system-for-solving-complex-tasks/), [Publication](https://www.microsoft.com/en-us/research/publication/magentic-one-a-generalist-multi-agent-system-for-solving-complex-tasks/), [GitHub](https://github.com/microsoft/autogen/tree/main/python/packages/autogen-magentic-one) | - | - |
| AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework | [arXiv](https://arxiv.org/abs/2308.08155) | Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, Chi Wang | ArXiv 2023 |


## Open Source Repos (with code)

| Title | Link | Author | Date |
|-------|------|--------|------|
| OLMo | [link]([https://arxiv.org/abs/2502.13189](https://github.com/allenai/OLMo)) | - | - |
| nanoGPT | [link](https://github.com/karpathy/nanoGPT) | - | - |
