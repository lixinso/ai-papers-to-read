# Best AI Papers to Read
### [That are publicly available]

## Papers

| Date | Title | Highlight | Author |
|------|-------|-----------|--------|
|------|GR00T N1: An Open Foundation Model for Generalist Humanoid Robots  [link1](https://arxiv.org/html/2503.14734v1#bib)   [link2](https://github.com/NVIDIA/Isaac-GR00T)  |-----------|--------|
|June 20, 2024|Vision Language Models in Autonomous Driving: A Survey and Outlook [link1](https://ieeexplore.ieee.org/document/10531702) [link2](https://github.com/ge25nab/Awesome-VLM-AD-ITS)|------|--------|
|Feb 26, 2021|Learning Transferable Visual Models From Natural Language Supervision (CLIP, 2021)|------|--------|
|Dec 31, 2025|mHC: Manifold-Constrained Hyper-Connections [link](https://arxiv.org/pdf/2512.24880)|------|DeepSeek-AI|
|November 7, 2025|Introducing Nested Learning: A new ML paradigm for continual learning [link](https://research.google/blog/introducing-nested-learning-a-new-ml-paradigm-for-continual-learning/)|Nested Learning - new ML paradigm for continual learning|Ali Behrouz, Vahab Mirrokni|
|2025-05|Generating Physically Stable and Buildable Brick Structures from Text [link](https://arxiv.org/abs/2505.05469)|BrickGPT|Ava Pun, Kangle Deng, Ruixuan Liu, Deva Ramanan, Changliu Liu, Jun-Yan Zhu|
|Aug 25, 2025|Neither Valid nor Reliable? Investigating the Use of LLMs as Judges [link](https://arxiv.org/abs/2508.18076)|------|--------|
|Aug 5, 2025|gpt-oss [link](https://github.com/openai/gpt-oss)|------|--------|
|Feb 19, 2025|The Ultra-Scale Playbook:Training LLMs on GPU Clusters [link](https://huggingface.co/spaces/nanotron/ultrascale-playbook?section=high-level_overview)|------|Hugging Face|
|July 30, 2025|Magentic-UI: Towards Human-in-the-loop Agentic Systems [link](https://arxiv.org/abs/2507.22358v1)|------|Microsoft Research AI Frontiers|
|June 26, 2025|Hierarchical Reasoning Model [link](https://arxiv.org/html/2506.21734v1)|------|Guan Wang1, Jin Li1, Yuhao Sun1, Xing Chen1, Changling Liu1, Yue Wu1, Meng Lu1, Sen Song2, Yasin Abbasi Yadkori1, Sapient Intelligence, Singapore|
|Jan 20, 2025|DeepSeek-R1 [link](https://github.com/deepseek-ai/DeepSeek-R1)|Distillation: Smaller Models Can Be Powerful Too|--------|
|2022|Training language models to follow instructions with human feedback|often called the InstructGPT paper-|Ouyang et al.,|
|Sébastien Bubeck, Ronen Eldan, Suriya Gunasekar|Textbooks Are All You Need (phi-1)|2306.11644|2023 06|
|2023 05|TinyStories: How Small Can Language Models Be and Still Speak Coherent English? [link](https://arxiv.org/abs/2305.07759)|------|Ronen Eldan, Yuanzhi Li|
|2023 06|Orca: Progressive Learning from Complex Explanation Traces of GPT-4 [link](https://arxiv.org/abs/2306.02707)|------|Subhabrata Mukherjee, Arindam Mitra, Hamid Palangi, Ahmed H. Awadallah|
|Apr 7, 2023|Generative Agents: Interactive Simulacra of Human Behavior [link](https://arxiv.org/abs/2304.03442)|------|Joon Sung Park, Joseph C. O'Brien, Carrie J. Cai, Meredith Ringel Morris, Percy Liang, Michael S. Bernstein|
|June 2, 2025|Small Language Models are the Future of Agentic AI [link](https://arxiv.org/pdf/2506.02153)|LLM-to-SLM Agent Conversion|--------|
|Mar 15, 2023|GPT-4 Technical Report [link](https://arxiv.org/abs/2303.08774)|GPT-4 report includes 26 expert exams; illustrates real-world barometers. State-of-the-art multimodal. Illustrates current limits and evaluation style of frontier models|--------|
|Jan 3, 2025|A Survey on Large Language Models with some Insights on their Capabilities and Limitations [link](https://arxiv.org/pdf/2501.04040)|------|--------|
|26 Jun 2025|Potemkin Understanding in Large Language Models [link](https://arxiv.org/abs/2506.21521)|You can not create AGI with LLM|Marina Mancoridis, Bec Weeks, Keyon Vafa, Sendhil Mullainathan|
|May 26, 2025|Vibe Coding vs. Agentic Coding: Fundamentals and Practical Implications of Agentic AI [link](https://arxiv.org/abs/2505.19443)|------|--------|
|11 June 2025|V-JEPA 2: Self-Supervised Video Models Enable Understanding, Prediction and Planning [link1](https://arxiv.org/abs/2506.09985) [link2](https://github.com/facebookresearch/vjepa2)|-|Mido Assran, Adrien Bardes, David Fan, et al. (29 co-authors, including Yann LeCun)|
|May 2025|Self-Evolving Curriculum for LLM Reasoning [link](https://arxiv.org/pdf/2505.14970)|------|Yoshua Bengio, et.al|
|Mar 2025|Advances and Challenges in Foundation Agents: From Brain-Inspired Intelligence to Evolutionary, Collaborative, and Safe Systems [link](https://arxiv.org/abs/2504.01990)|[Awesome-Foundation-Agents. Great paper list](https://github.com/FoundationAgents/awesome-foundation-agents)|Bang Liu, et al|
|January 17, 2025|Foundations of Large Language Models [link](https://arxiv.org/abs/2501.09223)|-|Tong Xiao and Jingbo Zhu, NLP Lab, Northeastern University & NiuTrans Research|
|Feb 17, 2025|Intuitive physics understanding emerges from self-supervised pretraining on natural videos [link](https://arxiv.org/pdf/2502.11831)|V-JEPA --a self-supervised video model|Yann LeCun|
|Jan 22, 2025|DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning [link](https://arxiv.org/abs/2501.12948)|-|-|
|Feb 5, 2024|DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Model [link](https://arxiv.org/pdf/2402.03300)|-|-|
|Apr 5, 2025|The Llama 4 herd: The beginning of a new era of natively multimodal AI innovation [link](https://ai.meta.com/blog/llama-4-multimodal-intelligence/)|Mixture-of-Experts (MoE) architecture|-|
|Mar 17, 2025|Why Do Multi-Agent LLM Systems Fail? [link1](https://github.com/multi-agent-systems-failure-taxonomy/MASFT) [link2](https://huggingface.co/papers/2503.13657)|-|-|
|Feb 18, 2025|MoBA: Mixture of Block Attention for Long-Context LLMs [link](https://arxiv.org/abs/2502.13189)|-|-|
|Feb 16, 2025|Native Sparse Attention: Hardware-Aligned and Natively Trainable Sparse Attention [link](https://arxiv.org/abs/2502.11089)|-|-|
|Jan 17, 2025|Foundations of Large Language Models [link](https://arxiv.org/abs/2501.09223)|-|-|
|Dec 27, 2024|DeepSeek-V3 Technical Report [link](https://github.com/deepseek-ai/DeepSeek-V3/blob/main/DeepSeek_V3.pdf)|-|-|
|May 29, 2024|Adaptive In-Conversion Team Building For Language Model Agent [link](https://arxiv.org/pdf/2405.19425)|-|-|
|Feb 28, 2024|Agent AI Towards a Holistic Intelligence [link](https://www.microsoft.com/en-us/research/uploads/prod/2024/02/AgentAI_p.pdf)|-|-|
|Nov 27, 2024|Large Language Model-Brained GUI Agents: A Survey [link](https://arxiv.org/pdf/2411.18279)|-|-|
|24 Oct 2024|MLE-bench: Evaluating Machine Learning Agents on Machine Learning Engineering [link](https://arxiv.org/abs/2410.07095)|-|OpenAI|
|Jan 7, 2024|Agent AI: Surveying the Horizons of Multimodal Interaction [link](https://arxiv.org/abs/2401.03568)|-|-|
|July 31, 2024|The Llama 3 Herd of Models [link1](https://scontent-sea1-1.xx.fbcdn.net/v/t39.2365-6/468347782_9231729823505907_4580471254289036098_n.pdf?_nc_cat=110&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=kMEnijIEZ-gQ7kNvgGkvbgV&_nc_zt=14&_nc_ht=scontent-sea1-1.xx&_nc_gid=AArxIIwO-RKxc0VHEWEXrCy&oh=00_AYBtVpVUKJJ3gf-Ev83Js4tUNmA_eQCHifdaJapFuVCJtA&oe=67508F80) [link2](https://ai.meta.com/research/publications/the-llama-3-herd-of-models/) [link3](https://ai.meta.com/blog/meta-llama-3-1/) [link4](./papers/The%20Llama%203%20Herd%20of%20Models/README.md)|-|-|
|Nov 4, 2024|Magentic-One: A Generalist Multi-Agent System for Solving Complex Tasks [link1](https://www.microsoft.com/en-us/research/articles/magentic-one-a-generalist-multi-agent-system-for-solving-complex-tasks/) [link2](https://www.microsoft.com/en-us/research/publication/magentic-one-a-generalist-multi-agent-system-for-solving-complex-tasks/) [link3](https://github.com/microsoft/autogen/tree/main/python/packages/autogen-magentic-one)|-|-|
|ArXiv 2023|AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework [link](https://arxiv.org/abs/2308.08155)|-|Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, Chi Wang|
|Mar 27, 2018|World Models David Ha, Jürgen Schmidhuber [link](https://arxiv.org/abs/1803.10122)|-|-|
|Jan 22, 2025|DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning [link](https://arxiv.org/abs/2501.12948)|-|-|
|June 12, 2017|Attention Is All You Need [link](https://arxiv.org/abs/1706.03762)|-|Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin|

## Open Source Repos (with code)

| Title | Author | Date |
|-------|--------|------|
| LeRobot https://huggingface.co/docs/lerobot/index |-|-|
|nanoChat [link](https://github.com/karpathy/nanochat)|karpathy|2025|
|Open-Sora [link](https://github.com/hpcaitech/Open-Sora)|-|-|
|NeMo [link](https://github.com/NVIDIA/NeMo)|Nvidia|-|
|OLMo [link](https://github.com/allenai/OLMo)|-|-|
|nanoGPT [link](https://github.com/karpathy/nanoGPT)|-|-|
|gigaGPT [link](https://github.com/Cerebras/gigaGPT)|-|-|
|Megatron-LM [link](https://github.com/NVIDIA/Megatron-LM)|-|-|
|gpt-2 [link](https://github.com/openai/gpt-2/tree/master)|-|-|
|grok-1 [link](https://github.com/xai-org/grok-1)|-|-|
|open-r1 [link](https://github.com/huggingface/open-r1)|-|-|
|EleutherAI gpt-neox [link](https://github.com/EleutherAI/gpt-neox)|-|-|
